{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET IA for HumanForYou - Entraînement et Évaluation du Modèle\n",
    "\n",
    "|Auteur|\n",
    "|---|\n",
    "|G. DUBOYS DE LAVIGERIE|\n",
    "|T. VILLETTE|\n",
    "|O. BOUSSARD|\n",
    "|A. BRICON|\n",
    "\n",
    "## Objectifs du Notebook\n",
    "\n",
    "Ce notebook a pour objectif de développer plusieurs modèles d'IA en utilisant les données prétraitées et de les évaluer sur un ensemble de test. Les étapes comprennent :\n",
    "\n",
    "1. **Division des données :** Séparation des données en ensembles d'entraînement et de test.\n",
    "2. **Entraînement des modèles :** Développement de plusieurs modèles d'IA avec les données d'entraînement.\n",
    "3. **Évaluation des modèles :** Mesure des performances de chaque modèle sur l'ensemble de test.\n",
    "4. **Sélection du meilleur modèle :** Analyse des résultats pour choisir le modèle offrant les performances les plus prometteuses.\n",
    "\n",
    "## Attendus\n",
    "\n",
    "À la fin de ce notebook, le modèle sera prêt à être déployé, accompagné d'une évaluation détaillée de ses performances.\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Avant d'exécuter ce notebook, assurez-vous d'avoir exécuté le notebook `data_preprocessing.ipynb` pour garantir que les données sont prêtes pour l'entraînement du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibilité entre Python 2 et Python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Imports nécessaires\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Assurer la stabilité du notebook entre différentes exécutions\n",
    "np.random.seed(42)\n",
    "\n",
    "# Affichage de figures directement dans le notebook\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ajustements des paramètres de l'affichage des figures\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Définition du chemin où sauver les figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"workflowDS\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)  # Assurez-vous que le dossier existe\n",
    "\n",
    "# Fonction pour sauvegarder les figures\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Sauvegarde de la figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignorer les avertissements inutiles (voir SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des données traitées réalisée dans le notebook `data_preprocessing.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) # Retirer la limite de colonnes à afficher\n",
    "\n",
    "def load_preprocessed_data(file_path='../datasets/data_preprocessing.csv'):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Charger les données prétraitées\n",
    "result = load_preprocessed_data()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division des données (jeu d'entraînement, jeu de test)\n",
    "Cette étape consiste à séparer les données en un jeu d'entraînement (80%) et un jeu de test (20%) afin d'évaluer la capacité du modèle à généraliser sur de nouvelles données. \n",
    "\n",
    "- Le **jeu d'entraînement** est utilisé pour former le modèle, lui fournissant une quantité suffisante de données pour apprendre les motifs et les relations présents dans nos données.\n",
    "\n",
    "- Le **jeu de test** permet de mesurer la performance du modèle sur des données non vues pendant l'entraînement, offrant ainsi une évaluation impartiale de sa capacité de généralisation.\n",
    "\n",
    "Le choix de la division 80/20 n'est pas arbitraire. Il s'agit d'une règle empirique bien établie dans le domaine de l'apprentissage machine, offrant un équilibre optimal entre la taille de l'ensemble d'entraînement nécessaire pour un apprentissage efficace et la capacité à évaluer le modèle de manière significative sur le jeu de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supposons que nous voulons prédire 'cat_nom__Attrition_Yes'\n",
    "y = result['cat_ord__Attrition']\n",
    "X = result.drop(['cat_ord__Attrition'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage d'un graphique\n",
    "fig, ax = plt.subplots(figsize=(2, 5))\n",
    "\n",
    "rect_train = plt.Rectangle((0, 0), 1, 0.8, color='red', alpha=0.5, label='Entraînement')\n",
    "rect_test = plt.Rectangle((0, 0.8), 1, 0.2, color='blue', alpha=0.5, label='Test')\n",
    "\n",
    "ax.add_patch(rect_train)\n",
    "ax.add_patch(rect_test)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Répartition des Données\")\n",
    "\n",
    "ax.text(0.5, 0.4, f'{len(X_train)}', ha='center', va='center', color='black', fontsize=8)\n",
    "ax.text(0.5, 0.9, f'{len(X_test)}', ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "ax.legend(loc='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choisir et Entraîner un modèle\n",
    "\n",
    "Avant de plonger dans les détails, il est essentiel de comprendre comment choisir, entraîner et évaluer un modèle. Une étape cruciale consiste à analyser les performances du modèle sur un ensemble de test et à utiliser des techniques comme la validation croisée pour garantir une évaluation robuste du modèle.\n",
    "\n",
    "**Fonction de validation croisée**\n",
    "\n",
    "La fonction `train_evaluate_model` ci-dessous illustre un processus générique d'entraînement et d'évaluation de modèles de régression. Cela garantit une approche standardisée dans notre notebook, simplifiant ainsi le processus et assurant une cohérence d'évaluation, indépendamment de l'algorithme sous-jacent.\n",
    "\n",
    "En utilisant la fonction `train_evaluate_model`, nous appliquons la validation croisée avec deux métriques :\n",
    "- **RMSE (Root Mean Square Error)** : Mesure la moyenne des erreurs au carré entre prédictions et valeurs réelles, avec prise de la racine carrée de cette moyenne.\n",
    "- **MAE (Mean Absolute Error)** : Autre métrique mesurant la moyenne des valeurs absolues des erreurs entre prédictions et valeurs réelles.\n",
    "\n",
    "Cette approche renforce l'évaluation des modèles en utilisant `scikit-learn` pour calculer le RMSE, la MAE, et la validation croisée, fournissant une évaluation complète de la performance du modèle.\n",
    "\n",
    "Il convient de noter que nous utilisons cette fonction pour chacun de nos modèles, assurant ainsi une comparaison équitable des performances entre les différentes approches algorithmiques que nous explorons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def train_model(trainer):\n",
    "    # Entraînement du modèle\n",
    "    trainer.fit(X_train, y_train)\n",
    "    \n",
    "    some_data = X_train.iloc[:5]\n",
    "    some_labels = y_train.iloc[:5]\n",
    "\n",
    "    # Et on effectue la prédiction :\n",
    "    print(\"Predictions:\", trainer.predict(some_data))\n",
    "    print(\"Labels:\", list(some_labels)) # vraies valeurs\n",
    "\n",
    "    # Prédictions sur les données de test\n",
    "    trainer_predictions = trainer.predict(X_test)\n",
    "    # Évaluation des prédictions sur les données de test\n",
    "    trainer_mse = mean_squared_error(y_test, trainer_predictions)\n",
    "    trainer_rmse = np.sqrt(trainer_mse)\n",
    "\n",
    "    # Affichage des métriques d'évaluation\n",
    "    print(\"MSE:\", trainer_mse)\n",
    "    print(\"RMSE:\", trainer_rmse)\n",
    "\n",
    "    # Validation croisée pour évaluer la performance du modèle\n",
    "    scores = cross_val_score(trainer, X_test, y_test,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    trainer_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "    # Affichage des scores de validation croisée\n",
    "    print(\"Cross-Validation Scores:\", trainer_rmse_scores)\n",
    "\n",
    "    # Affichage de la performance moyenne et de la variabilité du modèle\n",
    "    print(\"Mean RMSE:\", trainer_rmse_scores.mean())\n",
    "    print(\"RMSE Standard Deviation:\", trainer_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modèle de régression linéaire\n",
    "Entraînons un modèle de [_régression linéaire_](https://fr.wikipedia.org/wiki/R%C3%A9gression_lin%C3%A9aire) avec nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "train_model(lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modèle de régression par arbre de décision (DecisionTreeRegressor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create a DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "train_model(tree_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modèle RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(max_depth=15, max_features='log2', n_estimators=26,\n",
    "                      random_state=42)\n",
    "train_model(forest_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, precision_recall_curve\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b-\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "\n",
    "def display_scores(y_train_yes, y_train_pred, y_scores):\n",
    "    conf_matrix =  confusion_matrix(y_train_yes, y_train_pred)    \n",
    "    precision = precision_score(y_train_yes, y_train_pred)\n",
    "    recall = recall_score(y_train_yes, y_train_pred)\n",
    "    f1 = f1_score(y_train_yes, y_train_pred)\n",
    "    accuracy = accuracy_score(y_train_yes, y_train_pred)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_train_yes, y_scores)\n",
    "\n",
    "    print('Matrice de confusion : ', conf_matrix)\n",
    "    print('Précision : ', precision)\n",
    "    print('Recall : ', recall)\n",
    "    print('F1-score : ', f1)\n",
    "    print('Accuracy : ', accuracy) \n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "    plt.xlim([-700000, 700000])\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mélange de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "shuffle_index = np.random.permutation(len(X_train))\n",
    "X_train, y_train = X_train.iloc[shuffle_index], y_train.iloc[shuffle_index]\n",
    "\n",
    "# Garder les données avec attrition à True (> 0)\n",
    "y_train_yes = (y_train > 0)\n",
    "y_test_yes = (y_test > 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SDG Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_yes)\n",
    "\n",
    "predictions = sgd_clf.predict(X_test)\n",
    "y_scores = sgd_clf.decision_function(X_test)\n",
    "\n",
    "display_scores(y_test_yes, predictions, y_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "Utilisation de la méthode GridSearchCV afin de trouver les meilleurs hyperparamètres pour un modèle de régression RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [26], 'max_features': ['log2'], 'max_depth': [15]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    " \n",
    "# 5 sous-jeux de cross-val, ça fait en tout (12+6)*5=90 tours d'entraînement \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=10,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train,y_train )\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de la méthode GridSearchCV afin de trouver les meilleurs hyperparamètres pour le modèle SVR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de la méthode GridSearchCV afin de trouver les meilleurs hyperparamètres pour le modèle de régression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "param_grid = [\n",
    "    {'fit_intercept': [True, False]}\n",
    "]\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "grid_search = GridSearchCV(lin_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de la méthode GridSearchCV afin de trouver les meilleurs hyperparamètres pour le modèle de régression par arbre de décision (DecisionTreeRegressor)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
