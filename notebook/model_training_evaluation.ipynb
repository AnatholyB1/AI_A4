{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET IA for HumanForYou - Entraînement et Évaluation du Modèle\n",
    "\n",
    "|Auteur|\n",
    "|---|\n",
    "|G. DUBOYS DE LAVIGERIE|\n",
    "|T. VILLETTE|\n",
    "|O. BOUSSARD|\n",
    "|A. BRICON|\n",
    "\n",
    "## Objectifs du Notebook\n",
    "\n",
    "Ce notebook a pour objectif de développer plusieurs modèles d'IA en utilisant les données prétraitées et de les évaluer sur un ensemble de test. Les étapes comprennent :\n",
    "\n",
    "1. **Division des données :** Séparation des données en ensembles d'entraînement et de test.\n",
    "2. **Entraînement des modèles :** Développement de plusieurs modèles d'IA avec les données d'entraînement.\n",
    "3. **Évaluation des modèles :** Mesure des performances de chaque modèle sur l'ensemble de test.\n",
    "4. **Sélection du meilleur modèle :** Analyse des résultats pour choisir le modèle offrant les performances les plus prometteuses.\n",
    "\n",
    "## Attendus\n",
    "\n",
    "À la fin de ce notebook, le modèle sera prêt à être déployé, accompagné d'une évaluation détaillée de ses performances.\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Avant d'exécuter ce notebook, assurez-vous d'avoir exécuté le notebook `data_preprocessing.ipynb` pour garantir que les données sont prêtes pour l'entraînement du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibilité entre Python 2 et Python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Imports nécessaires\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Assurer la stabilité du notebook entre différentes exécutions\n",
    "np.random.seed(42)\n",
    "\n",
    "# Affichage de figures directement dans le notebook\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ajustements des paramètres de l'affichage des figures\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Définition du chemin où sauver les figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"workflowDS\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)  # Assurez-vous que le dossier existe\n",
    "\n",
    "# Fonction pour sauvegarder les figures\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Sauvegarde de la figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignorer les avertissements inutiles (voir SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des données traitées réalisée dans le notebook `data_preprocessing.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) # Retirer la limite de colonnes à afficher\n",
    "\n",
    "def load_preprocessed_data(file_path='../datasets/data_preprocessing.csv'):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Charger les données prétraitées\n",
    "result = load_preprocessed_data()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division des données (jeu d'entraînement, jeu de test)\n",
    "Cette étape consiste à séparer les données en un jeu d'entraînement (80%) et un jeu de test (20%) afin d'évaluer la capacité du modèle à généraliser sur de nouvelles données. \n",
    "\n",
    "- Le **jeu d'entraînement** est utilisé pour former le modèle, lui fournissant une quantité suffisante de données pour apprendre les motifs et les relations présents dans nos données.\n",
    "\n",
    "- Le **jeu de test** permet de mesurer la performance du modèle sur des données non vues pendant l'entraînement, offrant ainsi une évaluation impartiale de sa capacité de généralisation.\n",
    "\n",
    "Le choix de la division 80/20 n'est pas arbitraire. Il s'agit d'une règle empirique bien établie dans le domaine de l'apprentissage machine, offrant un équilibre optimal entre la taille de l'ensemble d'entraînement nécessaire pour un apprentissage efficace et la capacité à évaluer le modèle de manière significative sur le jeu de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supposons que nous voulons prédire 'cat_nom__Attrition_Yes'\n",
    "y = result['cat_ord__Attrition']\n",
    "X = result.drop(['cat_ord__Attrition'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage d'un graphique\n",
    "fig, ax = plt.subplots(figsize=(2, 5))\n",
    "\n",
    "rect_train = plt.Rectangle((0, 0), 1, 0.8, color='red', alpha=0.5, label='Entraînement')\n",
    "rect_test = plt.Rectangle((0, 0.8), 1, 0.2, color='blue', alpha=0.5, label='Test')\n",
    "\n",
    "ax.add_patch(rect_train)\n",
    "ax.add_patch(rect_test)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Répartition des Données\")\n",
    "\n",
    "ax.text(0.5, 0.4, f'{len(X_train)}', ha='center', va='center', color='black', fontsize=8)\n",
    "ax.text(0.5, 0.9, f'{len(X_test)}', ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "ax.legend(loc='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choisir et Entraîner un modèle\n",
    "\n",
    "Avant de plonger dans les détails, il est essentiel de comprendre comment choisir, entraîner et évaluer un modèle. Une étape cruciale consiste à analyser les performances du modèle sur un ensemble de test et à utiliser des techniques comme la validation croisée pour garantir une évaluation robuste du modèle.\n",
    "\n",
    "**Fonction de validation croisée**\n",
    "\n",
    "La fonction `train_evaluate_model` ci-dessous illustre un processus générique d'entraînement et d'évaluation de modèles de régression. Cela garantit une approche standardisée dans notre notebook, simplifiant ainsi le processus et assurant une cohérence d'évaluation, indépendamment de l'algorithme sous-jacent.\n",
    "\n",
    "En utilisant la fonction `train_evaluate_model`, nous appliquons la validation croisée avec deux métriques :\n",
    "- **RMSE (Root Mean Square Error)** : Mesure la moyenne des erreurs au carré entre prédictions et valeurs réelles, avec prise de la racine carrée de cette moyenne.\n",
    "- **MAE (Mean Absolute Error)** : Autre métrique mesurant la moyenne des valeurs absolues des erreurs entre prédictions et valeurs réelles.\n",
    "\n",
    "Cette approche renforce l'évaluation des modèles en utilisant `scikit-learn` pour calculer le RMSE, la MAE, et la validation croisée, fournissant une évaluation complète de la performance du modèle.\n",
    "\n",
    "Il convient de noter que nous utilisons cette fonction pour chacun de nos modèles, assurant ainsi une comparaison équitable des performances entre les différentes approches algorithmiques que nous explorons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def train_model(trainer):\n",
    "    # Entraînement du modèle\n",
    "    trainer.fit(X_train, y_train)\n",
    "    \n",
    "    some_data = X_train.iloc[:5]\n",
    "    some_labels = y_train.iloc[:5]\n",
    "\n",
    "    # Et on effectue la prédiction :\n",
    "    print(\"Predictions:\", trainer.predict(some_data))\n",
    "    print(\"Labels:\", list(some_labels)) # vraies valeurs\n",
    "\n",
    "    # Prédictions sur les données de test\n",
    "    trainer_predictions = trainer.predict(X_test)\n",
    "    # Évaluation des prédictions sur les données de test\n",
    "    trainer_mse = mean_squared_error(y_test, trainer_predictions)\n",
    "    trainer_rmse = np.sqrt(trainer_mse)\n",
    "\n",
    "    # Affichage des métriques d'évaluation\n",
    "    print(\"MSE:\", trainer_mse)\n",
    "    print(\"RMSE:\", trainer_rmse)\n",
    "\n",
    "    # Validation croisée pour évaluer la performance du modèle\n",
    "    scores = cross_val_score(trainer, X_test, y_test,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    trainer_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "    # Affichage des scores de validation croisée\n",
    "    print(\"Cross-Validation Scores:\", trainer_rmse_scores)\n",
    "\n",
    "    # Affichage de la performance moyenne et de la variabilité du modèle\n",
    "    print(\"Mean RMSE:\", trainer_rmse_scores.mean())\n",
    "    print(\"RMSE Standard Deviation:\", trainer_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle de régrission linéaire\n",
    "Entraînons un modèle de [_régression linéaire_](https://fr.wikipedia.org/wiki/R%C3%A9gression_lin%C3%A9aire) avec nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "train_model(lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle de régression par arbre de décision (DecisionTreeRegressor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create a DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "train_model(tree_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_reg = SVR(C=9.318742350231167, gamma=0.09849250205191949)\n",
    "train_model(svr_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(max_depth=15, max_features='log2', n_estimators=26,\n",
    "                      random_state=42)\n",
    "train_model(forest_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "Utilisation de la méthode GridSearchCV afin de trouver les meilleurs hyperparamètres pour un modèle de régression RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [26], 'max_features': ['log2'], 'max_depth': [15]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    " \n",
    "# 5 sous-jeux de cross-val, ça fait en tout (12+6)*5=90 tours d'entraînement \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=10,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train,y_train )\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = grid_search.best_estimator_.feature_importances_\n",
    "attributes = result.columns\n",
    "sorted(zip(feature_importance, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de la méthode GridSearchCV afin de trouver les meilleurs hyperparamètres pour le modèle SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "param_grid = [\n",
    "    # essaye 12 (3×4) combinaisons des hyperparametres\n",
    "    {'kernel': ['linear'], 'C': [10., 30., 100.]},\n",
    "    # puis essaye 6 (2×3) combinaisons avec le noyau RBF\n",
    "    {'kernel': ['rbf'], 'C': [10., 30., 100.],'gamma': [0.3, 1.0, 3.0]},\n",
    "]\n",
    "\n",
    "svr_reg = SVR()\n",
    "\n",
    "# 5 sous-jeux de cross-val, ça fait en tout (8+6*6)*5=350 tours d'entraînement \n",
    "grid_search = GridSearchCV(svr_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', verbose=2, n_jobs=4)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de la méthode GridSearchCV afin de trouver les meilleurs hyperparamètres pour le modèle de régression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "param_grid = [\n",
    "    {'fit_intercept': [True, False]}\n",
    "]\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "grid_search = GridSearchCV(lin_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de la méthode GridSearchCV afin de trouver les meilleurs hyperparamètres pour le modèle de régression par arbre de décision (DecisionTreeRegressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_grid = [\n",
    "    {'max_depth': [None, 5, 10, 15, 20], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 5]}\n",
    "]\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(tree_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nous avons effectué une recherche aléatoire (Randomized Search) avec la méthode RandomizedSearchCV afin de trouver les meilleurs hyperparamètres pour les  modèles SVR (Support Vector Regressor) et RandomForestRegressor. Nous n'avons testé cette méthode que sur ces 2 modèles car c'est les plus efficaces.\n",
    "La recherch aléatoire est  une technique de recherche qui consiste à choisir un élément au hasard dans une population pour déterminer si cela peut être considéré comme le meilleur ou le pire exemple possible. Nous avons testé cette méthode pour vérifier que les résultats de la recherche par grille étaient correctes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Paramètres pour SVR\n",
    "param_distributions_svr = {\n",
    "    'C': uniform(0.1, 10),\n",
    "    'gamma': uniform(0.01, 1),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "random_search_svr = RandomizedSearchCV(svr, param_distributions=param_distributions_svr, \n",
    "                                       n_iter=500, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search_svr.fit(X_train, y_train)\n",
    "\n",
    "print(random_search_svr.best_params_)\n",
    "print(random_search_svr.best_estimator_)\n",
    "\n",
    "# Paramètres pour RandomForestRegressor\n",
    "param_distributions_rf = {\n",
    "    'n_estimators': randint(10, 200),\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': randint(2, 20),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(rf, param_distributions=param_distributions_rf, \n",
    "                                      n_iter=500, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(random_search_rf.best_params_)\n",
    "print(random_search_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mélange aléatoire des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(len(X_train))\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation croisée (cross-validation)\n",
    "La validation croisée est une technique d'évaluation des modèles. Elle permet d'évaluer les performances des modèles d'apprentissage automatique.\n",
    "On utilise la méthode K -Folds. Cette méthode consiste séparer les données de manière aléatoire en K folds K faisant référence au nombre de groupes dans lequel l’échantillon sera divisé.Le modèle est entraîné sur une partie des données et testé sur une autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_yes = (y_train > 0)\n",
    "y_test_yes = (y_test > 0 )\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_yes)\n",
    "\n",
    "sgd_clf.predict(X_test)\n",
    "\n",
    "\n",
    "# cross-val a la mano\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_yes):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = (y_train_yes[train_index])\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = (y_train_yes[test_index])\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))\n",
    "\n",
    "# ⨯-val avec scikit-learn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_yes,cv=3 ,scoring=\"accuracy\" )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "predictions = never_5_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_yes, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix =  confusion_matrix(y_train_yes, y_train_pred)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_yes, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_yes, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_yes, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = sgd_clf.decision_function(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_yes, cv=3,\n",
    "                             method=\"decision_function\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_yes, y_scores)\n",
    "\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b-\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.xlim([-700000, 700000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"k-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_precision_vs_recall(precisions, recalls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_90 = (y_scores > 70000)\n",
    "\n",
    "precision_score(y_train_yes, y_train_pred_90), recall_score(y_train_yes, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_yes, y_scores)\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Supposons que y_true sont vos vraies étiquettes binaires, et y_scores sont les scores de décision de votre modèle\n",
    "auc_roc = roc_auc_score(y_train_yes, y_scores)\n",
    "\n",
    "print(\"AUC-ROC: \", auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42, n_estimators=10)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_yes, cv=3,\n",
    "                                    method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:, 1]\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_yes,y_scores_forest)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_train_yes, y_scores_forest)\n",
    "print(\"AUC: \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_forest = (y_scores_forest > 0.5)\n",
    "precision_score(y_train_yes, y_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_yes, y_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.fit(X_train, y_train_yes) # y_train ET NON y_train_5\n",
    "sgd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_scores = sgd_clf.decision_function(X_test)\n",
    "class_max_index = np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(max_iter=5, random_state=42))\n",
    "ovo_clf.fit(X_train, y_train_yes)\n",
    "ovo_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf.fit(X_train, y_train_yes)\n",
    "forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train_yes, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train_yes, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train_yes, cv=3)\n",
    "conf_mx = confusion_matrix(y_train_yes, y_train_pred)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n",
    "def plot_confusion_matrix(matrix):\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "plot_confusion_matrix(conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n",
    "plot_confusion_matrix(norm_conf_mx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
