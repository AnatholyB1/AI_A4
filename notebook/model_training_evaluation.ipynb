{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET IA for HumanForYou - Entraînement et Évaluation du Modèle\n",
    "\n",
    "|Auteur|\n",
    "|---|\n",
    "|G. DUBOYS DE LAVIGERIE|\n",
    "|T. VILLETTE|\n",
    "|O. BOUSSARD|\n",
    "|A. BRICON|\n",
    "\n",
    "## Objectifs du Notebook\n",
    "\n",
    "Ce notebook a pour objectif de développer plusieurs modèles d'IA en utilisant les données prétraitées et de les évaluer sur un ensemble de test. Les étapes comprennent :\n",
    "\n",
    "1. **Division des données :** Séparation des données en ensembles d'entraînement et de test.\n",
    "2. **Entraînement des modèles :** Développement de plusieurs modèles d'IA avec les données d'entraînement.\n",
    "3. **Évaluation des modèles :** Mesure des performances de chaque modèle sur l'ensemble de test.\n",
    "4. **Sélection du meilleur modèle :** Analyse des résultats pour choisir le modèle offrant les performances les plus prometteuses.\n",
    "\n",
    "## Attendus\n",
    "\n",
    "À la fin de ce notebook, le modèle sera prêt à être déployé, accompagné d'une évaluation détaillée de ses performances.\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Avant d'exécuter ce notebook, assurez-vous d'avoir exécuté le notebook `data_preprocessing.ipynb` pour garantir que les données sont prêtes pour l'entraînement du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibilité entre Python 2 et Python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Imports nécessaires\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Assurer la stabilité du notebook entre différentes exécutions\n",
    "np.random.seed(42)\n",
    "\n",
    "# Affichage de figures directement dans le notebook\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ajustements des paramètres de l'affichage des figures\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Définition du chemin où sauver les figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"workflowDS\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)  # Assurez-vous que le dossier existe\n",
    "\n",
    "# Fonction pour sauvegarder les figures\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Sauvegarde de la figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignorer les avertissements inutiles (voir SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des données traitées réalisée dans le notebook `data_preprocessing.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) # Retirer la limite de colonnes à afficher\n",
    "\n",
    "def load_preprocessed_data(file_path='../datasets/data_preprocessing.csv'):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Charger les données prétraitées\n",
    "result = load_preprocessed_data()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division des données (jeu d'entraînement, jeu de test)\n",
    "Cette étape consiste à séparer les données en un jeu d'entraînement (80%) et un jeu de test (20%) afin d'évaluer la capacité du modèle à généraliser sur de nouvelles données. \n",
    "\n",
    "- Le **jeu d'entraînement** est utilisé pour former le modèle, lui fournissant une quantité suffisante de données pour apprendre les motifs et les relations présents dans nos données.\n",
    "\n",
    "- Le **jeu de test** permet de mesurer la performance du modèle sur des données non vues pendant l'entraînement, offrant ainsi une évaluation impartiale de sa capacité de généralisation.\n",
    "\n",
    "Le choix de la division 80/20 n'est pas arbitraire. Il s'agit d'une règle empirique bien établie dans le domaine de l'apprentissage machine, offrant un équilibre optimal entre la taille de l'ensemble d'entraînement nécessaire pour un apprentissage efficace et la capacité à évaluer le modèle de manière significative sur le jeu de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supposons que nous voulons prédire 'cat_nom__Attrition_Yes'\n",
    "y = result['cat_ord__Attrition']\n",
    "X = result.drop(['cat_ord__Attrition'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage d'un graphique\n",
    "fig, ax = plt.subplots(figsize=(2, 5))\n",
    "\n",
    "rect_train = plt.Rectangle((0, 0), 1, 0.8, color='red', alpha=0.5, label='Entraînement')\n",
    "rect_test = plt.Rectangle((0, 0.8), 1, 0.2, color='blue', alpha=0.5, label='Test')\n",
    "\n",
    "ax.add_patch(rect_train)\n",
    "ax.add_patch(rect_test)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Répartition des Données\")\n",
    "\n",
    "ax.text(0.5, 0.4, f'{len(X_train)}', ha='center', va='center', color='black', fontsize=8)\n",
    "ax.text(0.5, 0.9, f'{len(X_test)}', ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "ax.legend(loc='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choisir et Entraîner un modèle\n",
    "\n",
    "Avant de plonger dans les détails, il est essentiel de comprendre comment choisir, entraîner et évaluer un modèle. Une étape cruciale consiste à analyser les performances du modèle sur un ensemble de test et à utiliser des techniques comme la validation croisée pour garantir une évaluation robuste du modèle.\n",
    "\n",
    "**Fonction de validation croisée**\n",
    "\n",
    "La fonction `train_evaluate_model` ci-dessous illustre un processus générique d'entraînement et d'évaluation de modèles de régression. Cela garantit une approche standardisée dans notre notebook, simplifiant ainsi le processus et assurant une cohérence d'évaluation, indépendamment de l'algorithme sous-jacent.\n",
    "\n",
    "En utilisant la fonction `train_evaluate_model`, nous appliquons la validation croisée avec deux métriques :\n",
    "- **RMSE (Root Mean Square Error)** : Mesure la moyenne des erreurs au carré entre prédictions et valeurs réelles, avec prise de la racine carrée de cette moyenne.\n",
    "- **MAE (Mean Absolute Error)** : Autre métrique mesurant la moyenne des valeurs absolues des erreurs entre prédictions et valeurs réelles.\n",
    "\n",
    "Cette approche renforce l'évaluation des modèles en utilisant `scikit-learn` pour calculer le RMSE, la MAE, et la validation croisée, fournissant une évaluation complète de la performance du modèle.\n",
    "\n",
    "Il convient de noter que nous utilisons cette fonction pour chacun de nos modèles, assurant ainsi une comparaison équitable des performances entre les différentes approches algorithmiques que nous explorons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def train_model(trainer):\n",
    "    # Entraînement du modèle\n",
    "    trainer.fit(X_train, y_train)\n",
    "    \n",
    "    some_data = X_train.iloc[:5]\n",
    "    some_labels = y_train.iloc[:5]\n",
    "\n",
    "    # Et on effectue la prédiction :\n",
    "    print(\"Predictions:\", trainer.predict(some_data))\n",
    "    print(\"Labels:\", list(some_labels)) # vraies valeurs\n",
    "\n",
    "    # Prédictions sur les données de test\n",
    "    trainer_predictions = trainer.predict(X_test)\n",
    "    # Évaluation des prédictions sur les données de test\n",
    "    trainer_mse = mean_squared_error(y_test, trainer_predictions)\n",
    "    trainer_rmse = np.sqrt(trainer_mse)\n",
    "\n",
    "    # Affichage des métriques d'évaluation\n",
    "    print(\"MSE:\", trainer_mse)\n",
    "    print(\"RMSE:\", trainer_rmse)\n",
    "\n",
    "    # Validation croisée pour évaluer la performance du modèle\n",
    "    scores = cross_val_score(trainer, X_test, y_test,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    trainer_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "    # Affichage des scores de validation croisée\n",
    "    print(\"Cross-Validation Scores:\", trainer_rmse_scores)\n",
    "\n",
    "    # Affichage de la performance moyenne et de la variabilité du modèle\n",
    "    print(\"Mean RMSE:\", trainer_rmse_scores.mean())\n",
    "    print(\"RMSE Standard Deviation:\", trainer_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle de régrission linéaire\n",
    "Entraînons un modèle de [_régression linéaire_](https://fr.wikipedia.org/wiki/R%C3%A9gression_lin%C3%A9aire) avec nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "train_model(lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle de régression par arbre de décision (DecisionTreeRegressor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create a DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "train_model(tree_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_reg = SVR(C=9.318742350231167, gamma=0.09849250205191949)\n",
    "train_model(svr_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(max_depth=15, max_features='log2', n_estimators=26,\n",
    "                      random_state=42)\n",
    "train_model(forest_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [26], 'max_features': ['log2'], 'max_depth': [15]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    " \n",
    "# 5 sous-jeux de cross-val, ça fait en tout (12+6)*5=90 tours d'entraînement \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=10,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train,y_train )\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = grid_search.best_estimator_.feature_importances_\n",
    "attributes = result.columns\n",
    "sorted(zip(feature_importance, attributes), reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
